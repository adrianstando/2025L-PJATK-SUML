{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Konwolucyjne sieci neuronowe\n",
    "\n",
    "Klasyfikacja obrazków na 10 klas (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck) - zbiór danych CIFAR10.\n",
    "\n",
    "https://keras.io/api/datasets/cifar10/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "set_seed(42)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if GPU or TPU is available\n",
    "\n",
    "def check_device():\n",
    "    print(\"Available devices:\")\n",
    "    print(tf.config.list_physical_devices())\n",
    "    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "    print(\"Num TPUs Available: \", len(tf.config.list_physical_devices('TPU')))\n",
    "    print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))\n",
    "\n",
    "check_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cifar10 dataset\n",
    "\n",
    "def load_cifar10():\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "    x_train = x_train.astype('float32') / 255.0\n",
    "    x_test = x_test.astype('float32') / 255.0\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create validation set from training data\n",
    "\n",
    "def create_validation_set(x_train, y_train, val_size=0.1):\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    val_indices = []\n",
    "    for i in range(num_classes):\n",
    "        class_indices = np.where(y_train == i)[0]\n",
    "        np.random.shuffle(class_indices)\n",
    "        val_count = int(len(class_indices) * val_size)\n",
    "        val_indices.extend(class_indices[:val_count])\n",
    "    x_val = x_train[val_indices]\n",
    "    y_val = y_train[val_indices]\n",
    "    x_train = np.delete(x_train, val_indices, axis=0)\n",
    "    y_train = np.delete(y_train, val_indices, axis=0)\n",
    "    return (x_train, y_train), (x_val, y_val)\n",
    "\n",
    "(x_train, y_train), (x_val, y_val) = create_validation_set(x_train, y_train, val_size=0.1)\n",
    "print(\"New training data shape:\", x_train.shape, y_train.shape)\n",
    "print(\"Validation data shape:\", x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some samples from the dataset for each class\n",
    "\n",
    "def visualize_samples(x, y):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    for i in range(10):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(x[y.flatten() == i][0])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "visualize_samples(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "\n",
    "def create_model():\n",
    "    # Define a CNN model\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.InputLayer(shape=(32, 32, 3)),\n",
    "        # 2-3 blocks of a convolutional layer and a pooling layer\n",
    "        # then flatten the output and add 2-3 dense layers\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOMEWORK\n",
    "\n",
    "# 1. Create a CNN model with 2-3 blocks of a convolutional layer and a pooling layer, then flatten the output and add 2-3 dense layers.\n",
    "# 2. Train the model on the training data and validate it on the validation data (expected accuracy on train, val and test > 60%).\n",
    "# 3. Evaluate the model on the test data.\n",
    "# 4. Visualize the training and validation loss and accuracy.\n",
    "# 5. Save the model.\n",
    "# 6. Create UI to load the model and make predictions on new images (use gradio or streamlit).\n",
    "# 7. Use 10 images from the Internet (provide a link) or your own, but do do not use CIFAR10 dataset, and make predictions. \n",
    "#    Attention: the images should be of the same size as CIFAR10 (32x32) and in RGB format. You can use PIL or OpenCV to resize the images.\n",
    "# (additional task) 8.* Use a more sophisticated network architecture (e.g. ResNet, VGG, etc.) and compare the results with the simple CNN model.\n",
    "# (additional task) 9.* Use data augmentation to improve the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
